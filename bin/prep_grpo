#!/usr/bin/env python3

import argparse
import json
import random
import pathlib

import lib.dataset as ds


parser = argparse.ArgumentParser(description='Prepare GRPO training data from multiple species')
parser.add_argument('species_dirs', nargs='+', type=str, metavar='<dir>',
    help='one or more species directories with fna.gz + gff.gz')
parser.add_argument('-o', '--output', type=str, required=True,
    metavar='<file>', help='output JSON file path')
parser.add_argument('-n', '--num_samples', type=int, default=5000,
    metavar='<int>', help='total number of GRPO samples [%(default)i]')
parser.add_argument('-w', '--window_size', type=int, default=20000,
    metavar='<int>', help='genomic window size [%(default)i]')
parser.add_argument('-s', '--seed', type=int, default=42,
    metavar='<int>', help='random seed [%(default)i]')

args = parser.parse_args()
random.seed(args.seed)

all_samples = []

for species_path in args.species_dirs:
    species_dir = pathlib.Path(species_path)
    if not species_dir.is_dir():
        print(f"SKIP: {species_path} (not a directory)")
        continue

    print(f"\nProcessing {species_dir.name}...")

    fna_path, gff_path = ds.find_genome_files(species_dir)
    sequences          = ds.lazy_fasta_open(fna_path)
    gene_index         = ds.parse_gff_to_gene_index(gff_path)
    gene_index         = ds.filter_canonical_transcripts(gene_index)
    coding_genes       = ds.extract_coding_genes(gene_index)

    samples = []
    for gene_id, gene_data in coding_genes.items():
        sample = ds.build_eval_sample(gene_id, gene_data, sequences, args.window_size)
        if sample:
            sample["species"] = species_dir.name
            samples.append(sample)

    print(f"  {len(samples)} valid samples")
    all_samples.extend(samples)

print(f"\nTotal samples across all species: {len(all_samples)}")

# Shuffle and select
random.shuffle(all_samples)
selected = all_samples[:args.num_samples]

# Write output
output_path = pathlib.Path(args.output)
output_path.parent.mkdir(parents=True, exist_ok=True)

with open(output_path, 'w') as f:
    json.dump(selected, f)

size_mb = output_path.stat().st_size / 1024 / 1024
print(f"\nSaved: {output_path} ({size_mb:.1f} MB)")

# Summary
species_set = set(s.get("species", "unknown") for s in selected)
total_exons = sum(s["num_exons"] for s in selected)
print(f"  Samples:  {len(selected)}")
print(f"  Species:  {len(species_set)} ({', '.join(sorted(species_set))})")
print(f"  Exons:    {total_exons}")
