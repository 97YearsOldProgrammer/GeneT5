#!/usr/bin/env python3

import argparse
import json
import random
import pathlib

import torch

import torch.utils.data as data_utils
import transformers as tf

import lib.dataset as ds
import lib.tokenizer as tk
import lib.model as mdl


DEFAULTS = {
    'max_input_len':  4096,
    'max_target_len': 2048,
    'batch_size':     4,
    'lr':             1e-4,
    'epochs':         3,
    'weight_decay':   0.1,
    'warmup_ratio':   0.1,
    'grad_accum':     64,
    'max_grad_norm':  1.0,
    'bucket_size':    256,
    'num_workers':    0,
}


def main():
    
    parser = argparse.ArgumentParser(description='Fine-tune GeneT5')
    parser.add_argument('train_bin', type=str, metavar='<train>',
        help='training binary file')
    parser.add_argument('val_bin', type=str, metavar='<val>',
        help='validation binary file')
    parser.add_argument('output_dir', type=str, metavar='<o>',
        help='output directory')
    parser.add_argument('model_path', type=str, metavar='<model>',
        help='pretrained model path')
    parser.add_argument('--checkpoint', required=False, type=str, default=None,
        metavar='<file>', help='resume from checkpoint')
    parser.add_argument('--epochs', required=False, type=int, default=DEFAULTS['epochs'],
        metavar='<int>', help='number of epochs [%(default)i]')
    parser.add_argument('--batch_size', required=False, type=int, default=DEFAULTS['batch_size'],
        metavar='<int>', help='batch size [%(default)i]')
    parser.add_argument('--lr', required=False, type=float, default=DEFAULTS['lr'],
        metavar='<float>', help='learning rate [%(default)g]')
    parser.add_argument('--max_input_len', required=False, type=int, default=DEFAULTS['max_input_len'],
        metavar='<int>', help='max input length [%(default)i]')
    parser.add_argument('--max_target_len', required=False, type=int, default=DEFAULTS['max_target_len'],
        metavar='<int>', help='max target length [%(default)i]')
    parser.add_argument('--grad_accum', required=False, type=int, default=DEFAULTS['grad_accum'],
        metavar='<int>', help='gradient accumulation steps [%(default)i]')
    parser.add_argument('--weight_decay', required=False, type=float, default=DEFAULTS['weight_decay'],
        metavar='<float>', help='weight decay [%(default).2f]')
    parser.add_argument('--warmup_ratio', required=False, type=float, default=DEFAULTS['warmup_ratio'],
        metavar='<float>', help='warmup ratio [%(default).2f]')
    parser.add_argument('--max_grad_norm', required=False, type=float, default=DEFAULTS['max_grad_norm'],
        metavar='<float>', help='max gradient norm [%(default).1f]')
    parser.add_argument('--bucket_size', required=False, type=int, default=DEFAULTS['bucket_size'],
        metavar='<int>', help='bucket size for batching [%(default)i]')
    parser.add_argument('--seed', required=False, type=int, default=42,
        metavar='<int>', help='random seed [%(default)i]')
    parser.add_argument('--save_every', required=False, type=int, default=1,
        metavar='<int>', help='save checkpoint every N epochs [%(default)i]')
    parser.add_argument('--num_workers', required=False, type=int, default=DEFAULTS['num_workers'],
        metavar='<int>', help='dataloader workers [%(default)i]')
    parser.add_argument('--early_stopping', required=False, type=int, default=None,
        metavar='<int>', help='early stopping patience')
    
    args = parser.parse_args()
    
    print(f"\n{' GeneT5 Fine-Tuning ':=^60}")
    
    # device setup
    if torch.cuda.is_available():
        device = torch.device('cuda')
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
    else:
        device = torch.device('cpu')
    print(f"Device: {device}")
    
    # set seeds
    torch.manual_seed(args.seed)
    random.seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    
    output_dir = pathlib.Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # load tokenizer
    print(f"\nLoading tokenizer...")
    tokenizer = tk.GeneTokenizer(pathlib.Path(args.model_path))
    print(f"  Vocab size: {len(tokenizer)}")
    
    # load model
    print(f"\nLoading model...")
    model = mdl.GeneT5.from_pretrained(pathlib.Path(args.model_path), device='cpu', dtype=torch.float32)
    model = model.to(device)
    
    stats = model.get_param_stats()
    print(f"  Trainable: {stats['total_trainable']:,}")
    print(f"  Frozen:    {stats['total_frozen']:,}")
    
    # load datasets
    print(f"\nLoading datasets...")
    
    train_dataset = ds.BinaryTrainDataset(
        args.train_bin, tokenizer, args.max_input_len, args.max_target_len, args.seed
    )
    
    val_dataset = ds.BinaryTrainDataset(
        args.val_bin, tokenizer, args.max_input_len, args.max_target_len, args.seed
    )
    
    print(f"  Train: {len(train_dataset)}")
    print(f"  Val:   {len(val_dataset)}")
    
    # setup dataloaders
    print(f"\nSetting up dataloaders...")
    
    collator = ds.DynamicPaddingCollator(tokenizer.pad_token_id, -100)
    
    train_sampler = ds.SmartBatchSampler(
        train_dataset.lengths, args.batch_size, args.bucket_size,
        drop_last=True, shuffle=True
    )
    
    train_loader = data_utils.DataLoader(
        train_dataset,
        batch_sampler = train_sampler,
        collate_fn    = collator,
        num_workers   = args.num_workers,
        pin_memory    = True,
    )
    
    val_sampler = ds.SmartBatchSampler(
        val_dataset.lengths, args.batch_size, args.bucket_size,
        drop_last=False, shuffle=False
    )
    
    val_loader = data_utils.DataLoader(
        val_dataset,
        batch_sampler = val_sampler,
        collate_fn    = collator,
        num_workers   = args.num_workers,
        pin_memory    = True,
    )
    
    print(f"  Train batches: {len(train_loader)}")
    print(f"  Val batches:   {len(val_loader)}")
    
    # setup optimizer
    print(f"\nSetting up optimizer...")
    
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr           = args.lr,
        betas        = (0.9, 0.95),
        weight_decay = args.weight_decay,
    )
    
    total_steps  = len(train_loader) * args.epochs // args.grad_accum
    warmup_steps = int(total_steps * args.warmup_ratio)
    
    scheduler = tf.get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)
    
    print(f"  Total steps:  {total_steps}")
    print(f"  Warmup steps: {warmup_steps}")
    
    # handle checkpoint
    start_epoch   = 0
    best_val_loss = float('inf')
    
    if args.checkpoint:
        checkpoint = torch.load(args.checkpoint, map_location=device)
        
        model.load_state_dict(checkpoint['model_state_dict'])
        
        if 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        start_epoch   = checkpoint.get('epoch', 0)
        best_val_loss = checkpoint.get('config', {}).get('best_val_loss', float('inf'))
        
        print(f"  Loaded checkpoint from {args.checkpoint} (epoch {start_epoch})")
    
    # save config
    config = {
        **vars(args),
        'vocab_size':    len(tokenizer),
        'train_samples': len(train_dataset),
        'val_samples':   len(val_dataset),
    }
    
    with open(output_dir / 'finetune_config.json', 'w') as f:
        json.dump(config, f, indent=2)
    
    # training loop
    print(f"\n{'=' * 60}")
    print('Training...')
    print(f"{'=' * 60}")
    
    dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16
    
    patience_counter = 0
    
    for epoch in range(start_epoch, args.epochs):
        print(f"\nEpoch {epoch + 1}/{args.epochs}")
        print('-' * 40)
        
        train_dataset.set_epoch(epoch)
        
        # train epoch
        model.train()
        total_train_loss = 0
        
        optimizer.zero_grad()
        
        for step, batch in enumerate(train_loader):
            batch = {k: v.to(device) for k, v in batch.items()}
            
            with torch.amp.autocast('cuda', dtype=dtype):
                outputs = model(
                    encoder_input_ids = batch['input_ids'],
                    decoder_input_ids = batch['labels'][:, :-1],
                    labels            = batch['labels'][:, 1:],
                )
                
                loss = outputs['loss'] / args.grad_accum
            
            loss.backward()
            
            if (step + 1) % args.grad_accum == 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            
            total_train_loss += loss.item() * args.grad_accum
        
        train_loss = total_train_loss / len(train_loader)
        
        # evaluate
        model.eval()
        total_val_loss = 0
        num_batches    = 0
        
        with torch.no_grad():
            for batch in val_loader:
                batch = {k: v.to(device) for k, v in batch.items()}
                
                with torch.amp.autocast('cuda', dtype=dtype):
                    outputs = model(
                        encoder_input_ids = batch['input_ids'],
                        decoder_input_ids = batch['labels'][:, :-1],
                        labels            = batch['labels'][:, 1:],
                    )
                
                total_val_loss += outputs['loss'].item()
                num_batches    += 1
        
        val_loss = total_val_loss / max(num_batches, 1)
        
        print(f"  Train: {train_loss:.4f} | Val: {val_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}")
        
        # checkpointing
        if val_loss < best_val_loss:
            best_val_loss    = val_loss
            patience_counter = 0
            
            print(f"  ✓ New best! Saving best_model.pt")
            
            save_path = output_dir / 'best_model.pt'
            save_path.parent.mkdir(parents=True, exist_ok=True)
            
            checkpoint = {
                'epoch':                epoch + 1,
                'model_state_dict':     model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config':               {'best_val_loss': best_val_loss, 'best_epoch': epoch + 1},
            }
            torch.save(checkpoint, save_path)
        else:
            patience_counter += 1
            es_str            = args.early_stopping if args.early_stopping else '∞'
            print(f"  No improvement ({patience_counter}/{es_str})")
            
            if args.early_stopping and patience_counter >= args.early_stopping:
                print(f"\n  Early stopping!")
                break
        
        if (epoch + 1) % args.save_every == 0:
            save_path = output_dir / 'checkpoint_latest.pt'
            save_path.parent.mkdir(parents=True, exist_ok=True)
            
            checkpoint = {
                'epoch':                epoch + 1,
                'model_state_dict':     model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config':               {'best_val_loss': best_val_loss},
            }
            torch.save(checkpoint, save_path)
    
    # save final
    print(f"\n{'=' * 60}")
    print('Saving final model...')
    
    model.save(output_dir / 'pytorch_model.bin')
    tokenizer.save_pretrained(output_dir)
    
    model_path = pathlib.Path(args.model_path)
    with open(model_path / 'config.json') as f:
        model_config = json.load(f)
    with open(output_dir / 'config.json', 'w') as f:
        json.dump(model_config, f, indent=2)
    
    print(f"\n{'=' * 60}")
    print(f"✓ Complete!")
    print(f"  Output: {output_dir}")
    print(f"  Best Val Loss: {best_val_loss:.4f}")
    print(f"{'=' * 60}")


if __name__ == '__main__':
    main()