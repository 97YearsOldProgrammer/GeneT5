
    
    import argparse
    
    parser = argparse.ArgumentParser(description="GeneT5 Inference")
    parser.add_argument("--model", "-m", required=True, help="Model checkpoint path")
    parser.add_argument("--input", "-i", required=True, help="Input FASTA file or sequence")
    parser.add_argument("--output", "-o", default="output", help="Output directory")
    parser.add_argument("--source", default="GeneT5", help="GFF source field")
    parser.add_argument("--max-length", type=int, default=512, help="Max generation length")
    parser.add_argument("--temperature", type=float, default=1.0, help="Sampling temperature")
    parser.add_argument("--top-k", type=int, default=50, help="Top-k sampling")
    parser.add_argument("--top-p", type=float, default=0.9, help="Top-p sampling")
    parser.add_argument("--batch-size", type=int, default=1, help="Batch size")
    parser.add_argument("--device", default=None, help="Device")
    
    args = parser.parse_args()
    
    device     = torch.device(args.device) if args.device else None
    inferencer = GeneT5Inference.from_pretrained(args.model, device=device)
    
    sequences, seqids = read_input(args.input)
    
    gen_config = GenerationConfig(
        max_length  = args.max_length,
        temperature = args.temperature,
        top_k       = args.top_k,
        top_p       = args.top_p,
    )
    
    results = inferencer.predict(
        sequences  = sequences,
        seqids     = seqids,
        output_dir = args.output,
        source     = args.source,
        gen_config = gen_config,
        batch_size = args.batch_size,
    )
    
    print(f"\nProcessed {len(results)} sequences")
    for r in results:
        print(f"  {r.metadata['seqid']}: {len(r.gff_features)} features -> {r.gff_path}")